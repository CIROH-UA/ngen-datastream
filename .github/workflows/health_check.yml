name: NRDS Health Check

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Start date (YYYYMMDD)'
        required: false
        default: ''
      end_date:
        description: 'End date (YYYYMMDD)'
        required: false
        default: ''
      vpus:
        description: 'VPUs (comma-separated or "all")'
        required: false
        default: 'all'
      run_types:
        description: 'Run types (comma-separated or "all")'
        required: false
        default: 'all'
  schedule:
    - cron: '0 0 * * *'  # Every day at midnight UTC

permissions:
  contents: read
  id-token: write

jobs:
  health-check:
    runs-on: ubuntu-latest
    outputs:
      has_failures: ${{ steps.health_check.outputs.has_failures }}
      failure_count: ${{ steps.health_check.outputs.failure_count }}
      failures: ${{ steps.health_check.outputs.failures }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install dependencies
        run: sudo apt-get update && sudo apt-get install -y jq

      - name: Verify health check script exists
        run: |
          if [ ! -f ./infra/aws/shell/check_datastream_outputs.sh ]; then
            echo "ERROR: Health check script not found at ./infra/aws/shell/check_datastream_outputs.sh"
            exit 1
          fi

      - name: Set Parameters
        id: params
        run: |
          # Default: check last 7 days for manual runs, yesterday for scheduled
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            if [ -n "${{ github.event.inputs.start_date }}" ]; then
              START_DATE="${{ github.event.inputs.start_date }}"
            else
              START_DATE=$(date -d '7 days ago' +%Y%m%d)
            fi
            
            if [ -n "${{ github.event.inputs.end_date }}" ]; then
              END_DATE="${{ github.event.inputs.end_date }}"
            else
              END_DATE=$(date -d 'yesterday' +%Y%m%d)
            fi
            
            VPUS="${{ github.event.inputs.vpus }}"
            RUN_TYPES="${{ github.event.inputs.run_types }}"
          else
            # Scheduled run - check yesterday only
            START_DATE=$(date -d 'yesterday' +%Y%m%d)
            END_DATE=$(date -d 'yesterday' +%Y%m%d)
            VPUS="all"
            RUN_TYPES="all"
          fi
          
          echo "start_date=$START_DATE" >> $GITHUB_OUTPUT
          echo "end_date=$END_DATE" >> $GITHUB_OUTPUT
          echo "vpus=$VPUS" >> $GITHUB_OUTPUT
          echo "run_types=$RUN_TYPES" >> $GITHUB_OUTPUT
          
          echo "Health check parameters:"
          echo "  Date range: $START_DATE to $END_DATE"
          echo "  VPUs: $VPUS"
          echo "  Run types: $RUN_TYPES"
    

      - name: Run Health Check and Capture Failures
        id: health_check
        run: |
          set +e  # Don't exit on error
          chmod +x ./infra/aws/shell/check_datastream_outputs.sh
          ./infra/aws/shell/check_datastream_outputs.sh \
            --start ${{ steps.params.outputs.start_date }} \
            --end ${{ steps.params.outputs.end_date }} \
            --vpus ${{ steps.params.outputs.vpus }} \
            --run_types ${{ steps.params.outputs.run_types }} 2>&1 | tee health_output.txt
          
          SCRIPT_EXIT_CODE=${PIPESTATUS[0]}
          set -e
          
          if [ $SCRIPT_EXIT_CODE -ne 0 ]; then
            echo "WARNING: Health check script exited with code $SCRIPT_EXIT_CODE"
            echo "Attempting to parse any available output..."
          fi
          
          # Parse failures into JSON array with validation
          failures=$(grep "missing" health_output.txt | awk '{print $1}' | while read url; do
            if [ -z "$url" ]; then
              continue
            fi
            
            date=$(echo "$url" | sed -n 's/.*ngen\.\([0-9]\{8\}\).*/\1/p')
            type=$(echo "$url" | sed -n 's/.*ngen\.[0-9]\{8\}\/\([^\/]*\).*/\1/p')
            cycle=$(echo "$url" | sed -n "s/.*\/$type\/\([0-9]\{2\}\).*/\1/p")
            
            # Try to match VPU pattern
            vpu=$(echo "$url" | sed -n 's/.*VPU_\([^\/]*\).*/\1/p')
            
            # If no VPU found, check if this is a forcing processor URL
            if [ -z "$vpu" ]; then
              # Forcing URLs look like: .../forcing_short_range/00/...
              # or: .../forcing_medium_range/12/3/...
              if echo "$url" | grep -q "forcing_"; then
                vpu="fp"
              fi
            fi
            
            # Skip if we couldn't parse required fields
            if [ -z "$date" ] || [ -z "$type" ] || [ -z "$cycle" ] || [ -z "$vpu" ]; then
              echo "WARNING: Failed to parse URL: $url" >&2
              continue
            fi
            
            if [[ "$type" == "medium_range" ]]; then
              ens=$(echo "$url" | sed -n 's/.*\/[0-9]\{2\}\/\([0-9]\)\/VPU.*/\1/p')
              # For fp medium_range, ensemble might be in a different position
              if [ -z "$ens" ] && [ "$vpu" = "fp" ]; then
                ens=$(echo "$url" | sed -n 's/.*\/[0-9]\{2\}\/\([0-9]\)\/.*/\1/p')
              fi
              echo "{\"date\":\"$date\",\"type\":\"$type\",\"cycle\":\"$cycle\",\"ensemble\":\"$ens\",\"vpu\":\"$vpu\",\"url\":\"$url\"}"
            else
              echo "{\"date\":\"$date\",\"type\":\"$type\",\"cycle\":\"$cycle\",\"vpu\":\"$vpu\",\"url\":\"$url\"}"
            fi
          done | jq -s '.')
          
          # Handle jq failure
          if [ $? -ne 0 ]; then
            echo "ERROR: Failed to parse failures with jq"
            failures="[]"
          fi
          
          # Set outputs
          echo "failures<<EOF" >> $GITHUB_OUTPUT
          echo "$failures" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          count=$(echo "$failures" | jq 'length')
          echo "has_failures=$([ $count -gt 0 ] && echo true || echo false)" >> $GITHUB_OUTPUT
          echo "failure_count=$count" >> $GITHUB_OUTPUT
          
          echo ""
          echo "Total failures found: $count"
          if [ $count -gt 0 ]; then
            echo "Failures:"
            echo "$failures" | jq '.'
          fi

      - name: Generate Rerun Execution Files
        if: steps.health_check.outputs.has_failures == 'true'
        working-directory: infra/aws
        run: |
          set -e
          
          FAILURES='${{ steps.health_check.outputs.failures }}'
          TEMPLATE_VPU="terraform/modules/schedules/executions/templates/execution_datastream_VPU_template.json"
          TEMPLATE_FP="terraform/modules/schedules/executions/templates/execution_datastream_fp_template.json"
          OUTPUT_DIR="terraform/modules/schedules/executions/reruns"
          
          mkdir -p "$OUTPUT_DIR"
          
          echo "Processing ${{ steps.health_check.outputs.failure_count }} failures..."
          
          # Forecast patterns mapping
          declare -A FORECAST_PATTERNS=(
            ["short_range"]="f001_f018"
            ["medium_range"]="f001_f240"
            ["analysis_assim_extend"]="tm27_tm00"
          )
          
          # Process each failure
          echo "$FAILURES" | jq -c '.[]' | while read -r failure; do
            DATE=$(echo "$failure" | jq -r '.date')
            TYPE=$(echo "$failure" | jq -r '.type')
            CYCLE=$(echo "$failure" | jq -r '.cycle')
            VPU=$(echo "$failure" | jq -r '.vpu')
            ENSEMBLE=$(echo "$failure" | jq -r '.ensemble // ""')
            
            echo "Processing: Date=$DATE, Type=$TYPE, Cycle=$CYCLE, VPU=$VPU, Ensemble=$ENSEMBLE"
            
            # Determine which template and output filename
            if [ "$VPU" = "fp" ]; then
              TEMPLATE="$TEMPLATE_FP"
              OUTPUT_FILE="$OUTPUT_DIR/rerun_${DATE}_${TYPE}_${CYCLE}_fp.json"
            else
              TEMPLATE="$TEMPLATE_VPU"
              if [ -n "$ENSEMBLE" ]; then
                OUTPUT_FILE="$OUTPUT_DIR/rerun_${DATE}_${TYPE}_${CYCLE}_${ENSEMBLE}_${VPU}.json"
              else
                OUTPUT_FILE="$OUTPUT_DIR/rerun_${DATE}_${TYPE}_${CYCLE}_${VPU}.json"
              fi
            fi
            
            # Load template
            EXEC_JSON=$(cat "$TEMPLATE")
            
            # Format END_DATE timestamp: YYYYMMDDHH00
            END_DATE="${DATE}${CYCLE}00"
            
            # Get forecast pattern
            FCST_PATTERN="${FORECAST_PATTERNS[$TYPE]}"
            
            if [ "$VPU" = "fp" ]; then
              # FP template: Replace DAILY and all placeholders
              EXEC_JSON=$(echo "$EXEC_JSON" | jq \
                --arg date "$DATE" \
                --arg type_upper "${TYPE^^}" \
                --arg type_lower "${TYPE,,}" \
                --arg init "$CYCLE" \
                --arg member "$ENSEMBLE" \
                '
                .commands = [.commands[] | 
                  gsub("DAILY"; $date) |
                  gsub("\\$RUN_TYPE_H"; $type_upper) |
                  gsub("\\$RUN_TYPE_L"; $type_lower) |
                  gsub("\\$INIT"; $init) |
                  # Handle $MEMBER patterns - match complete /$/MEMBER/ to avoid double slashes
                  gsub("/\\$MEMBER/"; if $member != "" then "/" + $member + "/" else "/" end) |
                  gsub("_\\$MEMBER"; if $member != "" then "_" + $member else "" end) |
                  gsub("\\$MEMBER"; $member)
                ] |
                .instance_parameters.TagSpecifications[0].Tags[0].Value = (
                  .instance_parameters.TagSpecifications[0].Tags[0].Value |
                  gsub("\\$RUN_TYPE_L"; $type_lower)
                )
              ')
            else
              # VPU template: Add -e flag, replace DAILY, and all placeholders
              NPROCS="3"  # Default, adjust based on instance type if needed
              
              EXEC_JSON=$(echo "$EXEC_JSON" | jq \
                --arg date "$DATE" \
                --arg end_date "$END_DATE" \
                --arg type_upper "${TYPE^^}" \
                --arg type_lower "${TYPE,,}" \
                --arg init "$CYCLE" \
                --arg member "$ENSEMBLE" \
                --arg vpu "$VPU" \
                --arg fcst "$FCST_PATTERN" \
                --arg nprocs "$NPROCS" \
                '
                .commands = [.commands[] | 
                  # Replace DAILY in paths
                  gsub("ngen\\.DAILY"; "ngen." + $date) |
                  # Add -e flag after -s DAILY
                  gsub("-s DAILY"; "-s DAILY -e " + $end_date) |
                  # Replace all placeholders
                  gsub("\\$VPU"; $vpu) |
                  gsub("\\$RUN_TYPE_H"; $type_upper) |
                  gsub("\\$RUN_TYPE_L"; $type_lower) |
                  gsub("\\$INIT"; $init) |
                  gsub("\\$FCST"; $fcst) |
                  gsub("\\$NPROCS"; $nprocs) |
                  # Handle $MEMBER patterns - match complete /$MEMBER/ to avoid double slashes
                  gsub("/\\$MEMBER/"; if $member != "" then "/" + $member + "/" else "/" end) |
                  gsub("_\\$MEMBER"; if $member != "" then "_" + $member else "" end) |
                  gsub("\\$MEMBER"; $member)
                ] |
                .instance_parameters.TagSpecifications[0].Tags[0].Value = (
                  .instance_parameters.TagSpecifications[0].Tags[0].Value |
                  gsub("\\$RUN_TYPE_L"; $type_lower) |
                  gsub("\\$VPU"; $vpu)
                )
              ')
            fi
            
            # Save modified execution file
            echo "$EXEC_JSON" | jq '.' > "$OUTPUT_FILE"
            echo "  ✓ Generated: $OUTPUT_FILE"
          done
          
          # Summary
          RERUN_COUNT=$(find "$OUTPUT_DIR" -name "rerun_*.json" 2>/dev/null | wc -l)
          echo ""
          echo "✓ Generated $RERUN_COUNT rerun execution files in $OUTPUT_DIR"


      - name: Display Generated Rerun Execution Files
        if: steps.health_check.outputs.has_failures == 'true'
        working-directory: infra/aws
        run: |
          OUTPUT_DIR="terraform/modules/schedules/executions/reruns"
          
          echo "=========================================="
          echo "GENERATED RERUN EXECUTION FILES"
          echo "=========================================="
          echo ""
          
          for file in "$OUTPUT_DIR"/rerun_*.json; do
            if [ -f "$file" ]; then
              echo "FILE: $(basename "$file")"
              echo "=========================================="
              cat "$file"
              echo ""
              echo ""
            fi
          done
      - name: Upload Rerun Execution Files
        if: steps.health_check.outputs.has_failures == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: rerun-execution-files
          path: infra/aws/terraform/modules/schedules/executions/reruns/*.json
          retention-days: 7
  failure-summary:
    name: Failure Summary
    needs: [health-check]
    if: always()
    runs-on: ubuntu-latest
    
    steps:
      - name: Generate Summary
        run: |
          echo "# NRDS Health Check Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ needs.health-check.outputs.has_failures }}" = "true" ]; then
            echo "## ⚠️ Failures Detected" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Total Failures:** ${{ needs.health-check.outputs.failure_count }}" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            
            # Display failures in a table
            echo "| Date | Type | Cycle | VPU | Ensemble | URL |" >> $GITHUB_STEP_SUMMARY
            echo "|------|------|-------|-----|----------|-----|" >> $GITHUB_STEP_SUMMARY
            
            echo '${{ needs.health-check.outputs.failures }}' | jq -r '.[] | 
              if .ensemble then 
                "| \(.date) | \(.type) | \(.cycle) | \(.vpu) | \(.ensemble) | [Link](\(.url)) |"
              else 
                "| \(.date) | \(.type) | \(.cycle) | \(.vpu) | N/A | [Link](\(.url)) |"
              end' >> $GITHUB_STEP_SUMMARY
            
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "_Rerun status unavailable: no rerun job was executed in this workflow run._" >> $GITHUB_STEP_SUMMARY
          else
            echo "## ✅ No Failures Detected" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "All health checks passed successfully!" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow Run:** [${{ github.run_id }}](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY



  validate-terraform:
    needs: [health-check]
    if: needs.health-check.outputs.has_failures == 'true'
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1

      - name: Configure AWS
        run: |
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws configure set region us-east-1 

      - name: Validate Terraform
        run: |
          cd infra/aws/terraform/modules/orchestration
          terraform init
          terraform validate
          chmod +x ../../../shell/import_resources.sh
          ../../../shell/import_resources.sh variables.tfvars
          terraform apply -var-file=variables.tfvars -auto-approve
          sleep 60

      - name: Download Rerun Execution Files
        uses: actions/download-artifact@v4
        with:
          name: rerun-execution-files
          path: infra/aws/terraform/modules/schedules/executions/reruns/

      - name: Create Key Pair
        run: |
          if ! aws ec2 describe-key-pairs --key-names "actions_key" --query 'KeyPairs[0].KeyName' --output text 2>/dev/null; then 
            aws ec2 create-key-pair --key-name "actions_key" --query 'KeyName' --output text
            echo "Key pair 'actions_key' created in AWS"
          else 
            echo "Key pair 'actions_key' already exists"
          fi

      - name: Execute Rerun Jobs
        working-directory: infra/aws/terraform/modules/orchestration
        run: |
          set -e
          
          # Get state machine ARN
          SM_ARN=$(cat ./sm_ARN.txt)
          echo "State Machine ARN: $SM_ARN"
          
          # Find all rerun execution files
          RERUN_DIR="../schedules/executions/reruns"
          
          if [ ! -d "$RERUN_DIR" ]; then
            echo "ERROR: Rerun directory not found at $RERUN_DIR"
            exit 1
          fi
          
          RERUN_FILES=$(find "$RERUN_DIR" -name "rerun_*.json" -type f | sort)
          FILE_COUNT=$(echo "$RERUN_FILES" | wc -l)
          
          if [ -z "$RERUN_FILES" ] || [ $FILE_COUNT -eq 0 ]; then
            echo "No rerun execution files found in $RERUN_DIR"
            exit 0
          fi
          
          echo "Found $FILE_COUNT rerun execution files to process"
          echo ""
          
          # S3 bucket and base path
          S3_BUCKET="ciroh-community-ngen-datastream"
          S3_BASE="v2.2"
          
          # Track execution status
          SUCCESSFUL=0
          FAILED=0
          VERIFICATION_FAILED=0
          declare -a FAILED_FILES
          declare -a VERIFICATION_FAILED_FILES
          
          # Parse failure info from job outputs
          FAILURES='${{ needs.health-check.outputs.failures }}'
          
          # Execute each rerun file
          for rerun_file in $RERUN_FILES; do
            filename=$(basename "$rerun_file")
            echo "=========================================="
            echo "Processing: $filename"
            echo "=========================================="
            
            # Generate unique execution name with timestamp
            EXEC_NAME="rerun_${filename%.json}_$(date -u +'%Y%m%d%H%M%S')"
            
            echo "Starting execution: $EXEC_NAME"
            
            # Start state machine execution
            EXECUTION_ARN=$(aws stepfunctions start-execution \
              --state-machine-arn "$SM_ARN" \
              --name "$EXEC_NAME" \
              --input "file://$rerun_file" \
              --region us-east-1 \
              --query 'executionArn' \
              --output text)
            
            echo "Execution ARN: $EXECUTION_ARN"
            
            # Poll for completion
            STATUS="RUNNING"
            TIMEOUT=3600  # 1 hour timeout
            ELAPSED=0
            
            while [ "$STATUS" = "RUNNING" ] && [ $ELAPSED -lt $TIMEOUT ]; do
              sleep 10
              ELAPSED=$((ELAPSED + 10))
              
              STATUS=$(aws stepfunctions describe-execution \
                --execution-arn "$EXECUTION_ARN" \
                --region us-east-1 \
                --query 'status' \
                --output text)
              
              echo "Status after ${ELAPSED}s: $STATUS"
            done
            
            # Check final status
            if [ "$STATUS" = "SUCCEEDED" ]; then
              echo "✓ Step Functions execution succeeded: $filename"
              SUCCESSFUL=$((SUCCESSFUL + 1))
              
              # Verify merkdir.file in S3
              echo "Verifying merkdir.file in S3 output..."
              
              # Extract metadata from filename
              FILE_BASE="${filename#rerun_}"
              FILE_BASE="${FILE_BASE%.json}"
              
              # Find matching failure record
              FAILURE_RECORD=$(echo "$FAILURES" | jq -c --arg fname "$FILE_BASE" '.[] | 
                select(
                  (.date + "_" + .type + "_" + .cycle + 
                  (if .ensemble != "" and .ensemble != null then "_" + .ensemble else "" end) + 
                  (if .vpu != "fp" then "_" + .vpu else "_fp" end)) == $fname
                )'
              )
              
              if [ -n "$FAILURE_RECORD" ]; then
                DATE=$(echo "$FAILURE_RECORD" | jq -r '.date')
                TYPE=$(echo "$FAILURE_RECORD" | jq -r '.type')
                CYCLE=$(echo "$FAILURE_RECORD" | jq -r '.cycle')
                VPU=$(echo "$FAILURE_RECORD" | jq -r '.vpu')
                ENSEMBLE=$(echo "$FAILURE_RECORD" | jq -r '.ensemble // ""')
                
                # Construct S3 path for merkdir.file
                if [ "$VPU" = "fp" ]; then
                  # Forcing processor path
                  if [ -n "$ENSEMBLE" ]; then
                    S3_PATH="s3://${S3_BUCKET}/${S3_BASE}/ngen.${DATE}/forcing_${TYPE}/${CYCLE}/${ENSEMBLE}/merkdir.file"
                  else
                    S3_PATH="s3://${S3_BUCKET}/${S3_BASE}/ngen.${DATE}/forcing_${TYPE}/${CYCLE}/merkdir.file"
                  fi
                else
                  # VPU path
                  if [ -n "$ENSEMBLE" ]; then
                    S3_PATH="s3://${S3_BUCKET}/${S3_BASE}/ngen.${DATE}/${TYPE}/${CYCLE}/${ENSEMBLE}/VPU_${VPU}/merkdir.file"
                  else
                    S3_PATH="s3://${S3_BUCKET}/${S3_BASE}/ngen.${DATE}/${TYPE}/${CYCLE}/VPU_${VPU}/merkdir.file"
                  fi
                fi
                
                echo "Expected S3 path: $S3_PATH"
                
                # Check if merkdir.file exists in S3
                if aws s3 ls "$S3_PATH" --region us-east-1 >/dev/null 2>&1; then
                  echo "✓ VERIFIED: merkdir.file exists in S3"
                else
                  echo "✗ VERIFICATION FAILED: merkdir.file not found in S3"
                  echo "  Expected: $S3_PATH"
                  VERIFICATION_FAILED=$((VERIFICATION_FAILED + 1))
                  VERIFICATION_FAILED_FILES+=("$filename - merkdir.file missing")
                  # Don't count as successful if verification failed
                  SUCCESSFUL=$((SUCCESSFUL - 1))
                  FAILED=$((FAILED + 1))
                fi
              else
                echo "⚠ WARNING: Could not find matching failure record for verification"
              fi
              
            elif [ "$STATUS" = "FAILED" ]; then
              echo "✗ FAILED: $filename"
              FAILED=$((FAILED + 1))
              FAILED_FILES+=("$filename")
            elif [ "$STATUS" = "TIMED_OUT" ] || [ $ELAPSED -ge $TIMEOUT ]; then
              echo "⏱ TIMEOUT: $filename (exceeded ${TIMEOUT}s)"
              FAILED=$((FAILED + 1))
              FAILED_FILES+=("$filename (timeout)")
            else
              echo "⚠ UNKNOWN STATUS: $filename - $STATUS"
              FAILED=$((FAILED + 1))
              FAILED_FILES+=("$filename ($STATUS)")
            fi
            
            echo ""
          done
          
          # Summary
          echo "=========================================="
          echo "EXECUTION SUMMARY"
          echo "=========================================="
          echo "Total files: $FILE_COUNT"
          echo "Successful: $SUCCESSFUL"
          echo "Failed: $FAILED"
          echo "Verification Failed: $VERIFICATION_FAILED"
          echo ""
          
          if [ $FAILED -gt 0 ]; then
            echo "Failed executions:"
            for failed in "${FAILED_FILES[@]}"; do
              echo "  - $failed"
            done
            echo ""
          fi
          
          if [ $VERIFICATION_FAILED -gt 0 ]; then
            echo "Failed S3 verifications (merkdir.file missing):"
            for failed in "${VERIFICATION_FAILED_FILES[@]}"; do
              echo "  - $failed"
            done
            echo ""
          fi
          
          if [ $FAILED -gt 0 ] || [ $VERIFICATION_FAILED -gt 0 ]; then
            echo "⚠ Some reruns failed or merkdir.file not found in S3. Check AWS Step Functions console for details."
            exit 1
          else
            echo "✓ All reruns completed successfully and merkdir.file verified in S3!"
          fi


      - name: Tear down infra
        if: always()
        run: |
          cd infra/aws/terraform/modules/orchestration
          terraform destroy -var-file=variables.tfvars -auto-approve
          sleep 60
