name: Terraform PR Validation

on:
  workflow_dispatch:   
  push:
    branches:
      - main
      - infra_deployment
    paths:
      - 'infra/aws/terraform/**'
      - '.github/workflows/terraform-*.yml'
      - 'infra/aws/python/src/research_datastream/**'
  pull_request:
    branches:
      - main
      - infra_deployment
    paths:
      - 'infra/aws/terraform/**'
      - '.github/workflows/terraform-*.yml'
      - 'infra/aws/python/src/research_datastream/**'
env:
  TF_VAR_FILE: variables.tfvars
  AWS_REGION: us-east-2
  TERRAFORM_VERSION: 1.9.0


jobs:
  generate-executions:
    name: Generate VPU Execution Files
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'
    
    - name: Install Python dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y jq
        pip install --upgrade pip
        pip install --upgrade awscli
        pip install --upgrade awscli boto3 pandas

    - name: Configure AWS
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region us-east-2    

    - name: Generate execution files
      working-directory: infra/aws
      run: |
        echo "Working directory: $(pwd)"
        echo "Generating VPU execution files..."
        python python/src/research_datastream/gen_vpu_execs.py \
        --arch arm \
        --inputs terraform/modules/schedules/config/execution_forecast_inputs.json \
        --ami_file terraform/modules/schedules/config/community_ami.txt \
        --exec_template_vpu terraform/modules/schedules/executions/templates/execution_datastream_VPU_template.json \
        --exec_template_fp terraform/modules/schedules/executions/templates/execution_datastream_fp_template.json \
        --out_dir terraform/modules/schedules/executions

        echo "::notice::Execution files generated successfully"

  terraform-check:
    name: Terraform Quality Checks
    needs: generate-executions
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: infra/aws/terraform
    
    permissions:
      contents: read
      pull-requests: write
      id-token: write
      security-events: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'
    
    - name: Install Python dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y jq
        pip install --upgrade pip
        pip install --upgrade awscli
        pip install --upgrade awscli boto3 pandas


    - name: Configure AWS
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region us-east-2    
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}
        terraform_wrapper: false
    
    - name: Terraform Format Check
      id: fmt
      run: terraform fmt -check -recursive
      continue-on-error: true
    
    - name: Terraform Init
      id: init
      run: terraform init -backend-config="key=terraform/${{ github.repository }}.tfstate"
 
    - name: Terraform Validate
      id: validate
      run: terraform validate -no-color
    
    - name: Check for tfvars files
      id: check_tfvars
      run: |
        echo "Checking for required tfvars files..."
        
        # Check if the main tfvars file exists
        if [ ! -f "${{ env.TF_VAR_FILE }}" ]; then
          echo "::error::Missing required tfvars file: ${{ env.TF_VAR_FILE }}"
          exit 1
        fi
        
        echo "::notice::Found tfvars file: ${{ env.TF_VAR_FILE }}"
        
        # Validate tfvars syntax
        terraform fmt -check "${{ env.TF_VAR_FILE }}" || {
          echo "::warning::File ${{ env.TF_VAR_FILE }} is not properly formatted"
        }
        
        # Optionally check for environment-specific tfvars if they exist
        if [ -d "environments" ]; then
          tfvars_count=$(find environments -name "*.tfvars" -type f | wc -l)
          if [ "$tfvars_count" -gt 0 ]; then
            echo "::notice::Found $tfvars_count additional environment tfvars file(s)"
            find environments -name "*.tfvars" -type f
          fi
        fi

    - name: Run tfsec Security Scan
      id: tfsec
      uses: aquasecurity/tfsec-pr-commenter-action@v1.3.1
      with:
        github_token: ${{ github.token }}
        working_directory: infra/aws/terraform
        soft_fail_commenter: true
    
    - name: Run Checkov Security Scan
      id: checkov
      uses: bridgecrewio/checkov-action@v12
      with:
        directory: infra/aws/terraform
        framework: terraform
        output_format: cli,sarif
        output_file_path: console,results.sarif
        soft_fail: true
    
    - name: Upload Checkov Results
      if: always()
      uses: github/codeql-action/upload-sarif@v3
      with:
        sarif_file: results.sarif
      continue-on-error: true
    
    - name: Terraform Plan
      id: plan
      run: |
        terraform plan -var-file=./${{ env.TF_VAR_FILE }} -no-color -out=tfplan
        terraform show -no-color tfplan > plan_output.txt
      continue-on-error: true
    
    - name: Upload Plan Artifact
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan-${{ github.sha }}
        path: infra/aws/terraform/tfplan
        retention-days: 10
    
    - name: Upload Plan Output
      uses: actions/upload-artifact@v4
      with:
        name: terraform-plan-output-${{ github.sha }}
        path: infra/aws/terraform/plan_output.txt
        retention-days: 10
    
    - name: Check for Plan Failures
      if: steps.plan.outcome == 'failure'
      run: |
        echo "::warning::Terraform plan failed but continuing workflow"
        echo "Plan failed with errors. Check the plan output for details."
      continue-on-error: true
    
    - name: Check for Format Failures
      if: steps.fmt.outcome == 'failure'
      run: |
        echo "::error::Terraform files are not properly formatted. Run 'terraform fmt -recursive' locally."
      continue-on-error: true
    
        
  terraform-apply:
    name: Terraform Apply
    needs: terraform-check
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/infra_deployment'
    defaults:
      run:
        working-directory: infra/aws/terraform
    
    permissions:
      contents: read
      id-token: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'
    
    - name: Install Python dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y jq
        pip install --upgrade pip
        pip install --upgrade awscli boto3 pandas

    - name: Configure AWS
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region us-east-2

    - name: Generate execution files
      working-directory: infra/aws
      run: |
        echo "Working directory: $(pwd)"
        echo "Generating VPU execution files..."
        python python/src/research_datastream/gen_vpu_execs.py \
        --arch arm \
        --inputs terraform/modules/schedules/config/execution_forecast_inputs.json \
        --ami_file terraform/modules/schedules/config/community_ami.txt \
        --exec_template_vpu terraform/modules/schedules/executions/templates/execution_datastream_VPU_template.json \
        --exec_template_fp terraform/modules/schedules/executions/templates/execution_datastream_fp_template.json \
        --out_dir terraform/modules/schedules/executions

        echo "::notice::Execution files generated successfully"
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: ${{ env.TERRAFORM_VERSION }}
        terraform_wrapper: false
    
    - name: Terraform Init
      run: terraform init -backend-config="key=terraform/${{ github.repository }}.tfstate"
    
    - name: Download Plan Artifact
      uses: actions/download-artifact@v4
      with:
        name: terraform-plan-${{ github.sha }}
        path: infra/aws/terraform
    
    - name: Terraform Apply
      id: apply
      run: |
        echo "::notice::Starting Terraform Apply..."
        terraform apply -auto-approve tfplan
        echo "::notice::Terraform Apply completed successfully"
    
    - name: Terraform Output
      if: success()
      run: |
        echo "::group::Terraform Outputs"
        terraform output -json > terraform_outputs.json
        cat terraform_outputs.json
        echo "::endgroup::"
    
    - name: Upload Terraform Outputs
      if: success()
      uses: actions/upload-artifact@v4
      with:
        name: terraform-outputs-${{ github.sha }}
        path: infra/aws/terraform/terraform_outputs.json
        retention-days: 30     
        
  test-all-vpus:
    runs-on: ubuntu-latest
    needs: terraform-apply
    strategy:
      fail-fast: false
      matrix:
        vpu: ["01", "02", "03N", "03S", "03W", "04", "05", "06", "07", "08", "09", "10L", "10U", "11", "12", "13", "14", "15", "16", "17", "18"]    
    env:
      VPU: ${{ matrix.vpu }}
      DATE: 20250905
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          pip install --upgrade awscli boto3 pandas

      - name: Generate execution files using Python script
        run: |
          cd infra/aws
          python python/src/research_datastream/gen_vpu_execs.py \
            --arch arm \
            --inputs terraform/modules/schedules/config/execution_forecast_inputs.json \
            --ami_file terraform/modules/schedules/config/community_ami.txt \
            --exec_template_vpu terraform/modules/schedules/executions/templates/execution_datastream_VPU_template.json \
            --exec_template_fp terraform/modules/schedules/executions/templates/execution_datastream_fp_template.json \
            --out_dir test_executions

      - name: Modify execution for testing (Short Range)
        run: |
          cd infra/aws
          short_range_execution_file="test_executions/short_range/00/execution_datastream_${{ env.VPU }}.json"
          # Update for testing with custom tags and S3 prefix
        
          jq --arg DATE "${{ env.DATE }}" --arg VPU "${{ env.VPU }}" '
            .instance_parameters.TagSpecifications = [{
              "ResourceType": "instance",
              "Tags": [
                {"Key": "Project", "Value": "fp_test_git_actions_vpu_\($VPU)"},
                {"Key": "AMI_Version", "Value": "test-version"}
              ]
            }] |
            .commands |= map(
                # swap placeholder only; no regex near quotes
                gsub("__S3_PREFIX__"; "tests/short_range/VPU_\($VPU)")
              | gsub("ngen.DAILY"; "ngen.\($DATE)")
              | gsub("-s DAILY"; "-s DAILY -e \($DATE)0000")
            )
          ' "$short_range_execution_file" > temp_short_range_execution.json
          mv temp_short_range_execution.json "$short_range_execution_file"
          cat test_executions/short_range/00/execution_datastream_${{ env.VPU }}.json
         
                    
      
      - name: Modify execution for testing (Medium Range)
        run: |
          cd infra/aws
          medium_range_execution_file="test_executions/medium_range/00/1/execution_datastream_${{ env.VPU }}.json"
      
          # Update for testing with custom tags and S3 prefix
          jq --arg DATE "${{ env.DATE }}" --arg VPU "${{ env.VPU }}" '
            .instance_parameters.TagSpecifications = [{
              "ResourceType": "instance",
              "Tags": [
                {"Key": "Project", "Value": "fp_test_git_actions_vpu_\($VPU)"},
                {"Key": "AMI_Version", "Value": "test-version"}
              ]
            }] |
            .commands |= map(
                gsub("__S3_PREFIX__"; "tests/medium_range/VPU_\($VPU)")
              | gsub("ngen.DAILY"; "ngen.\($DATE)")
              | gsub("-s DAILY"; "-s DAILY -e \($DATE)0000")
            )
          ' "$medium_range_execution_file" > temp_medium_range_execution.json
          mv temp_medium_range_execution.json "$medium_range_execution_file"
          cat test_executions/medium_range/00/1/execution_datastream_${{ env.VPU }}.json          

      - name: Check and create AWS key pair
        run: |
          if ! aws ec2 describe-key-pairs --key-names "actions_key" --query 'KeyPairs[0].KeyName' --output text 2>/dev/null; then 
            aws ec2 create-key-pair --key-name "actions_key" --query 'KeyName' --output text
            echo "Key pair 'actions_key' created"
          else 
            echo "Key pair 'actions_key' already exists"
          fi

      - name: Start and monitor Step Functions execution (Short Range)
        id: stepfunction_short
        run: |
          cd infra/aws
          short_range_execution_file="test_executions/short_range/00/execution_datastream_${{ env.VPU }}.json"
          cat test_executions/short_range/00/execution_datastream_${{ env.VPU }}.json
          TS=$(env TZ=US/Eastern date +'%Y%m%d%H%M%S%3N')   # ms resolution
          NAME="sr-vpu-${{ env.VPU }}-${TS}-${{ github.run_id }}-${{ github.run_attempt }}"
          execution_arn=$(aws stepfunctions start-execution \
            --state-machine-arn $(aws ssm get-parameter --name "/datastream/state-machine-arn" --query 'Parameter.Value' --output text) \
            --name "$NAME" \
            --input "file://$short_range_execution_file" \
            --region us-east-2 \
            --query 'executionArn' --output text)
          
          echo "Execution ARN: $execution_arn"
          
          status="RUNNING"
          while [ "$status" != "SUCCEEDED" ]; do
            status=$(aws stepfunctions describe-execution --execution-arn "$execution_arn" --region us-east-2 --query 'status' --output text)
            echo "Current status: $status"
            if [ "$status" == "FAILED" ]; then
              echo "State machine execution failed for VPU ${{ env.VPU }}!"
              echo "stepfunction_failed=true" >> "$GITHUB_OUTPUT"
              exit 1
            fi
            sleep 5
          done
          echo "State machine execution succeeded for VPU ${{ env.VPU }}!"
          echo "stepfunction_failed=false" >> "$GITHUB_OUTPUT"
           
      - name: Verify output files (Short Range)
        if: matrix.vpu != '10U' && matrix.vpu != '17'
        run: |
          echo "Checking if processing created output files for VPU ${{ env.VPU }}..."
          
          file_list=$(aws s3 ls s3://ciroh-community-ngen-datastream/tests/short_range/VPU_${{ env.VPU }}/ --recursive 2>/dev/null || echo "")
          
          if [ -n "$file_list" ]; then
            echo "SUCCESS: VPU ${{ env.VPU }} processing completed!"
            echo "$file_list"
            file_count=$(echo "$file_list" | wc -l)
            echo "Total files created for VPU ${{ env.VPU }}: $file_count (short_range) "
          else
            echo "FAILED: No output files created for Short Range VPU ${{ env.VPU }}"
            exit 1
          fi

      - name: Verify specific file (Short Range)
        if: matrix.vpu != '10U' && matrix.vpu != '17'
        run: |
          curl -fSs -o test.txt https://ciroh-community-ngen-datastream.s3.amazonaws.com/tests/short_range/VPU_${{ env.VPU }}/merkdir.file || { 
            echo "Error: File not found or request failed"; exit 1; 
          } 


      - name: Start and monitor Step Functions execution (Medium Range)
        id: stepfunction_medium
        run: |
          cd infra/aws
          medium_range_execution_file="test_executions/medium_range/00/1/execution_datastream_${{ env.VPU }}.json"
          cat test_executions/medium_range/00/1/execution_datastream_${{ env.VPU }}.json
          TS=$(env TZ=US/Eastern date +'%Y%m%d%H%M%S%3N')   # ms resolution
          NAME="mr-vpu-${{ env.VPU }}-${TS}-${{ github.run_id }}-${{ github.run_attempt }}"
          execution_arn=$(aws stepfunctions start-execution \
            --state-machine-arn $(aws ssm get-parameter --name "/datastream/state-machine-arn" --query 'Parameter.Value' --output text) \
            --name "$NAME" \
            --input "file://$medium_range_execution_file" \
            --region us-east-2 \
            --query 'executionArn' --output text)
          
          echo "Execution ARN: $execution_arn"
          
          status="RUNNING"
          while [ "$status" != "SUCCEEDED" ]; do
            status=$(aws stepfunctions describe-execution --execution-arn "$execution_arn" --region us-east-2 --query 'status' --output text)
            echo "Current status: $status"
            if [ "$status" == "FAILED" ]; then
              echo "State machine execution failed for VPU ${{ env.VPU }}!"
              echo "stepfunction_failed=true" >> "$GITHUB_OUTPUT"
              exit 1
            fi
            sleep 5
          done
          echo "State machine execution succeeded for VPU ${{ env.VPU }}!"
          echo "stepfunction_failed=false" >> "$GITHUB_OUTPUT"

      - name: Verify output files Medium Range
        if: matrix.vpu != '10U' && matrix.vpu != '17'
        run: |
          echo "Checking if processing created output files for VPU ${{ env.VPU }}..."
          file_list=$(aws s3 ls s3://ciroh-community-ngen-datastream/tests/medium_range/VPU_${{ env.VPU }}/ --recursive 2>/dev/null || echo "")
          
          if [ -n "$file_list" ]; then
            echo "SUCCESS: VPU ${{ env.VPU }} processing completed!"
            echo "$file_list"
            file_count=$(echo "$file_list" | wc -l)
            echo "Total files created for VPU ${{ env.VPU }}: $file_count (medium_range) "
          else
            echo "FAILED: No output files created for Medium Range VPU ${{ env.VPU }}"
            exit 1
          fi

      - name: Verify specific file (Medium Range)
        if: matrix.vpu != '10U' && matrix.vpu != '17'
        run: |
          curl -fSs -o test.txt https://ciroh-community-ngen-datastream.s3.amazonaws.com/tests/medium_range/VPU_${{ env.VPU }}/merkdir.file || { 
            echo "Error: File not found or request failed"; exit 1; 
          } 
          
      - name: Clean up
        if: always()
        run: |
          aws s3 rm --recursive s3://ciroh-community-ngen-datastream/tests/short_range/VPU_${{ env.VPU }} || echo "No files to delete"
          aws s3 rm --recursive s3://ciroh-community-ngen-datastream/tests/medium_range/VPU_${{ env.VPU }} || echo "No files to delete"

  terraform-destroy:
    name: Terraform Destroy Test Resources
    needs: test-all-vpus
    runs-on: ubuntu-latest
    if: always()
    defaults:
      run:
        working-directory: infra/aws/terraform

    permissions:
      contents: read
      id-token: write

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Configure AWS
        run: |
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws configure set region ${{ env.AWS_REGION }}
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
          terraform_wrapper: false
      
      - name: Terraform Init
        run: terraform init -backend-config="key=terraform/${{ github.repository }}.tfstate"
        continue-on-error: true
      
      - name: Pre-Destroy Cleanup - Stop All Running Resources
        run: |
          echo "::group::Pre-destroy cleanup of dynamic resources"
          
          # Stop all running Step Functions executions
          echo "Stopping all running Step Functions executions..."
          STATE_MACHINE_ARN=$(aws ssm get-parameter --name "/datastream/state-machine-arn" --query 'Parameter.Value' --output text 2>/dev/null || echo "")
          
          if [ -n "$STATE_MACHINE_ARN" ]; then
            aws stepfunctions list-executions \
              --state-machine-arn "$STATE_MACHINE_ARN" \
              --status-filter RUNNING \
              --region ${{ env.AWS_REGION }} \
              --query 'executions[*].executionArn' \
              --output text | while read -r arn; do
                if [ -n "$arn" ]; then
                  echo "Stopping execution: $arn"
                  aws stepfunctions stop-execution --execution-arn "$arn" --region ${{ env.AWS_REGION }} 2>/dev/null || echo "Already stopped"
                fi
              done
          fi
          
          # Terminate all test instances
          echo "Terminating all test EC2 instances..."
          TEST_INSTANCE_IDS=$(aws ec2 describe-instances \
            --filters \
              "Name=tag:Project,Values=fp_test_git_actions_vpu_*" \
              "Name=instance-state-name,Values=running,pending,stopping,stopped" \
            --query 'Reservations[*].Instances[*].InstanceId' \
            --output text \
            --region ${{ env.AWS_REGION }})
          
          if [ -n "$TEST_INSTANCE_IDS" ]; then
            echo "Terminating instances: $TEST_INSTANCE_IDS"
            aws ec2 terminate-instances --instance-ids $TEST_INSTANCE_IDS --region ${{ env.AWS_REGION }} || echo "Some instances already terminating"
            echo "Waiting for instances to terminate..."
            sleep 30
          else
            echo "No test instances found"
          fi
          
          # Clean up all test S3 data
          echo "Cleaning up all test S3 data..."
          aws s3 rm --recursive s3://ciroh-community-ngen-datastream/tests/ 2>/dev/null || echo "No test files to delete"
          
          echo "::endgroup::"
        continue-on-error: true

      - name: Wait for Resources to Stabilize
        run: |
          echo "Waiting 60 seconds for resources to stabilize before destroy..."
          sleep 60
        continue-on-error: true

      - name: Terraform Destroy - Attempt 1
        id: destroy_attempt1
        run: |
          echo "::notice::Starting Terraform Destroy (Attempt 1)..."
          terraform destroy -var-file=./${{ env.TF_VAR_FILE }} -auto-approve
          echo "::notice::Terraform Destroy completed successfully"
        continue-on-error: true

      - name: Terraform Destroy - Attempt 2 (if first failed)
        if: steps.destroy_attempt1.outcome == 'failure'
        id: destroy_attempt2
        run: |
          echo "::warning::First destroy attempt failed, waiting 30s and retrying..."
          sleep 30
          terraform destroy -var-file=./${{ env.TF_VAR_FILE }} -auto-approve
        continue-on-error: true

      - name: Terraform Destroy - Attempt 3 (if second failed)
        if: steps.destroy_attempt2.outcome == 'failure'
        id: destroy_attempt3
        run: |
          echo "::warning::Second destroy attempt failed, waiting 60s and retrying..."
          sleep 60
          terraform destroy -var-file=./${{ env.TF_VAR_FILE }} -auto-approve
        continue-on-error: true

      - name: Force Cleanup Remaining Resources
        if: steps.destroy_attempt3.outcome == 'failure'
        run: |
          echo "::group::Force cleanup of remaining resources"
          
          echo "Checking for remaining resources in Terraform state..."
          terraform state list || echo "Could not list state"
          
          echo "Attempting targeted destroys for common problem resources..."
          
          # Get actual resources from state and try targeted destroy
          terraform state list 2>/dev/null | grep -E "(aws_lambda_|aws_iam_role|aws_security_group)" | while read resource; do
            echo "Attempting to destroy: $resource"
            terraform destroy -target="$resource" -auto-approve 2>/dev/null || echo "Could not destroy $resource"
          done
          
          echo "::endgroup::"
        continue-on-error: true

      - name: Manual Cleanup of Orphaned Resources
        if: always()
        run: |
          echo "::group::Manual cleanup of any orphaned resources"
          
          # Delete any remaining EBS volumes
          echo "Checking for orphaned EBS volumes..."
          VOLUMES=$(aws ec2 describe-volumes \
            --filters "Name=status,Values=available" \
            --query 'Volumes[*].VolumeId' \
            --output text \
            --region ${{ env.AWS_REGION }})
          
          if [ -n "$VOLUMES" ]; then
            for vol in $VOLUMES; do
              echo "Deleting volume: $vol"
              aws ec2 delete-volume --volume-id "$vol" --region ${{ env.AWS_REGION }} 2>/dev/null || echo "Could not delete $vol"
            done
          else
            echo "No orphaned volumes found"
          fi
          
          # Delete any remaining snapshots
          echo "Checking for orphaned snapshots..."
          SNAPSHOTS=$(aws ec2 describe-snapshots \
            --owner-ids self \
            --query 'Snapshots[*].SnapshotId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          
          if [ -n "$SNAPSHOTS" ]; then
            for snap in $SNAPSHOTS; do
              echo "Deleting snapshot: $snap"
              aws ec2 delete-snapshot --snapshot-id "$snap" --region ${{ env.AWS_REGION }} 2>/dev/null || echo "Could not delete $snap"
            done
          else
            echo "No orphaned snapshots found"
          fi
          
          # Delete any remaining network interfaces
          echo "Checking for orphaned network interfaces..."
          ENIS=$(aws ec2 describe-network-interfaces \
            --filters "Name=status,Values=available" \
            --query 'NetworkInterfaces[*].NetworkInterfaceId' \
            --output text \
            --region ${{ env.AWS_REGION }} 2>/dev/null || echo "")
          
          if [ -n "$ENIS" ]; then
            for eni in $ENIS; do
              echo "Deleting network interface: $eni"
              aws ec2 delete-network-interface --network-interface-id "$eni" --region ${{ env.AWS_REGION }} 2>/dev/null || echo "Could not delete $eni"
            done
          else
            echo "No orphaned network interfaces found"
          fi
          
          echo "::endgroup::"
        continue-on-error: true

      - name: Final State Check
        if: always()
        run: |
          echo "::group::Final Terraform State"
          REMAINING=$(terraform state list 2>/dev/null | wc -l)
          if [ "$REMAINING" -gt 0 ]; then
            echo "⚠️  WARNING: $REMAINING resources still in state:"
            terraform state list
          else
            echo "✓ State is clean - all resources destroyed"
          fi
          echo "::endgroup::"
        continue-on-error: true

      - name: Report Destroy Status
        if: always()
        run: |
          if [ "${{ steps.destroy_attempt1.outcome }}" == "success" ]; then
            echo "::notice::✓ Terraform destroy completed successfully on first attempt"
          elif [ "${{ steps.destroy_attempt2.outcome }}" == "success" ]; then
            echo "::warning::✓ Terraform destroy completed successfully on second attempt"
          elif [ "${{ steps.destroy_attempt3.outcome }}" == "success" ]; then
            echo "::warning::✓ Terraform destroy completed successfully on third attempt"
          else
            echo "::error::✗ Terraform destroy failed after 3 attempts. Manual cleanup may be required."
            echo "::error::Check the workflow logs and AWS console for remaining resources"
            exit 1
          fi