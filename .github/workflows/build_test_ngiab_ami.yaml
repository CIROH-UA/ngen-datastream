name: Test Datastream NGIAB AMI Integration

on:
  workflow_dispatch:
    inputs:
      ds_tag:
        description: 'Datastream Docker tag'
        required: false
        default: 'latest'
        type: string
      fp_tag:
        description: 'Forcing Processor Docker tag'
        required: false
        default: 'latest'
        type: string
      ngiab_tag:
        description: 'NGIAB Docker tag'
        required: false
        default: 'latest'
        type: string

permissions:
  contents: write

jobs:
  test-ngiab-dev-integration:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up QEMU
      uses: docker/setup-qemu-action@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3      

    - name: Configure AWS
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region us-east-1    
        export AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
        export AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Build docker containers
      run: |        
        ./scripts/docker_builds.sh -f -d
        docker images

    - name: Base test and NWM_RETRO_V3
      run: |        
        sudo rm -rf $(pwd)/data/datastream_test        
        ./scripts/datastream -s 202006200100 -e 202006200200 -C NWM_RETRO_V3 -d $(pwd)/data/datastream_test -g https://ngen-datastream.s3.us-east-2.amazonaws.com/palisade.gpkg -R $(pwd)/configs/ngen/realization_sloth_nom_cfe_pet.json

  test-ngiab-ds-latest-integration:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up QEMU
      uses: docker/setup-qemu-action@v3

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3      

    - name: Display trigger information
      run: |
        echo "Workflow triggered manually with versions:"
        echo "DS_TAG: ${{ inputs.ds_tag }}"
        echo "FP_TAG: ${{ inputs.fp_tag }}"
        echo "NGIAB_TAG: ${{ inputs.ngiab_tag }}"


    - name: Configure AWS
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region us-east-1    
        export AWS_ACCESS_KEY_ID=${{ secrets.AWS_ACCESS_KEY_ID }}
        export AWS_SECRET_ACCESS_KEY=${{ secrets.AWS_SECRET_ACCESS_KEY }}

    - name: Base test and NWM_RETRO_V3
      run: |        
        sudo rm -rf $(pwd)/data/datastream_test        
        # Export version tags for datastream script
        export DS_TAG="${{ inputs.ds_tag }}"
        export FP_TAG="${{ inputs.fp_tag }}"
        export NGIAB_TAG="${{ inputs.ngiab_tag }}"
        ./scripts/datastream -s 202006200100 -e 202006200200 -C NWM_RETRO_V3 -d $(pwd)/data/datastream_test -g https://ngen-datastream.s3.us-east-2.amazonaws.com/palisade.gpkg -R $(pwd)/configs/ngen/realization_sloth_nom_cfe_pet.json

  bump-version:
    needs: [test-ngiab-dev-integration, test-ngiab-ds-latest-integration]
    if: always() && (needs.test-ngiab-dev-integration.result == 'success' || needs.test-ngiab-ds-latest-integration.result == 'success')
    runs-on: ubuntu-latest
    outputs:
      new_version: ${{ steps.version.outputs.new_version }}
    steps:
    - uses: actions/checkout@v4
    - name: Bump version
      id: version
      run: |
        current_version=$(grep 'datastream-ami-version:' ./ami_version.yml | sed 's/.*"\([0-9]*\)\.\([0-9]*\)\.\([0-9]*\)".*/\1.\2.\3/')
        major=$(echo $current_version | cut -d. -f1)
        minor=$(echo $current_version | cut -d. -f2)
        patch=0
        new_minor=$((minor + 1))
        new_version="$major.$new_minor.$patch"
        
        echo "new_version=$new_version" >> "$GITHUB_OUTPUT"
        
        sed -i "s/datastream-ami-version: \"[0-9]*\.[0-9]*\.[0-9]*\"/datastream-ami-version: \"$new_version\"/" ./ami_version.yml
        
        git config user.name "bot"
        git config user.email "bot@github.com"
        git add ./ami_version.yml
        git commit -m "bump version to $new_version [skip ci]"
        git push

  build-test-push-ami:
    needs: bump-version
    runs-on: ubuntu-latest
    outputs:
      ds_tag: ${{ inputs.ds_tag }}
      fp_tag: ${{ inputs.fp_tag }}
      ngiab_tag: ${{ inputs.ngiab_tag }}
      ds_ami_version: ${{ steps.changes.outputs.ds_ami_version }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref_name }}
          fetch-depth: 1

      - name: Install yq
        run: |
          sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
          sudo chmod +x /usr/local/bin/yq

      - name: Get version info
        id: changes
        shell: bash
        run: |
          set -euo pipefail
          
          # Get current AMI version
          CURRENT_DS_AMI=$(yq -r e '."datastream-ami-version"' ami_version.yml)
          echo "ds_ami_version=$CURRENT_DS_AMI" >> "$GITHUB_OUTPUT"
          
          echo "Using Docker tags:"
          echo "DS_TAG=${{ inputs.ds_tag }}"
          echo "FP_TAG=${{ inputs.fp_tag }}"
          echo "NGIAB_TAG=${{ inputs.ngiab_tag }}"

      - name: Configure AWS
        run: |
          aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws configure set region us-east-1        

      - name: Build AMI on AWS (N Virginia)
        run: |
          ami_version=datastream-"${{ steps.changes.outputs.ds_ami_version }}"     
          echo "Building AMI: $ami_version"
          echo "With Docker tags: DS=${{ inputs.ds_tag }}, FP=${{ inputs.fp_tag }}, NGIAB=${{ inputs.ngiab_tag }}"
          
          export AMI_NAME="$ami_version"
          export DS_TAG="${{ inputs.ds_tag }}"
          export FP_TAG="${{ inputs.fp_tag }}"
          export NGIAB_TAG="${{ inputs.ngiab_tag }}"
          chmod +x scripts/create_ami.sh
          ./scripts/create_ami.sh
          
  get-ami-info:
    needs: build-test-push-ami
    runs-on: ubuntu-latest
    outputs:
      ami_id: ${{ steps.get-ami.outputs.ami_id }}
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Get AMI ID
        id: get-ami
        run: |
          ami_name="datastream-${{ needs.build-test-push-ami.outputs.ds_ami_version }}"
          ami_id=$(aws ec2 describe-images \
            --owners self \
            --filters "Name=name,Values=$ami_name" \
            --query 'Images[0].ImageId' \
            --output text \
            --region us-east-1)
          echo "ami_id=$ami_id" >> "$GITHUB_OUTPUT"

  test-research-datastream-forcingprocessing:
    needs: [build-test-push-ami, get-ami-info]
    runs-on: ubuntu-latest
    env:
      DATE: 20250801
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          pip install --upgrade awscli

      - name: Download and modify execution JSON
        run: |
          cd research_datastream/terraform_community
          
          # Use the AMI ID from the get-ami-info job
          ami_id="${{ needs.get-ami-info.outputs.ami_id }}"
          ami_name="datastream-${{ needs.build-test-push-ami.outputs.ds_ami_version }}"
          
          # Verify AMI ID is valid
          if [ "$ami_id" == "None" ] || [ "$ami_id" == "" ] || [ "$ami_id" == "null" ]; then
            echo "Invalid AMI ID: $ami_id"
            echo "Available AMIs:"
            aws ec2 describe-images --owners self --query 'Images[*].[Name,ImageId]' --output table --region us-east-1
            exit 1
          fi
          
          echo "Using AMI ID: $ami_id for AMI name: $ami_name"
          echo "With Docker versions: DS=${{ needs.build-test-push-ami.outputs.ds_tag }}, FP=${{ needs.build-test-push-ami.outputs.fp_tag }}, NGIAB=${{ needs.build-test-push-ami.outputs.ngiab_tag }}"
          
          # Download the proven working execution JSON from S3
          aws s3 cp s3://ciroh-community-ngen-datastream/v2.2/ngen.${{ env.DATE }}/forcing_short_range/00/metadata/execution.json execution.json
          
          # Replace the working AMI with custom one
          jq --arg ami "$ami_id" '.instance_parameters.ImageId = $ami' execution.json > execution_updated.json
          mv execution_updated.json execution.json
          
          # Replace Docker image tags with manually specified versions
          sed -i "s|DS_TAG=1.0.1|DS_TAG=${{ needs.build-test-push-ami.outputs.ds_tag }}|g" execution.json
          sed -i "s|NGIAB_TAG=v0.0.0|NGIAB_TAG=${{ needs.build-test-push-ami.outputs.ngiab_tag }}|g" execution.json
          
          # Show key info
          echo "AMI replacement completed for FP test"
          echo "New AMI ID: $(jq -r '.instance_parameters.ImageId' execution.json)"
          
          jq --arg DATE "${{ env.DATE }}" 'del(.instance_parameters.MaxCount, .instance_parameters.MinCount, .instance_parameters.InstanceId, .t0, .ii_s3_object_checked, .retry_attempt, .region) | .instance_parameters.TagSpecifications = [{"ResourceType": "instance", "Tags": [{"Key": "Project", "Value": "fp_test_git_actions"}, {"Key": "DS_TAG", "Value": "${{ needs.build-test-push-ami.outputs.ds_tag }}"}, {"Key": "NGIAB_TAG", "Value": "${{ needs.build-test-push-ami.outputs.ngiab_tag }}"}]}] | .commands |= map(sub("--s3_prefix(?i) \\K[^ ]+"; "tests/short_range/fp'\''")) | .commands |= map(gsub("--start_date DAILY"; "--start_date DAILY --end_date \($DATE)0000"))' execution.json > temp.json

      - name: Check and create AWS key pair
        run: |
          cd research_datastream/terraform_community
          if ! aws ec2 describe-key-pairs --key-names "actions_key" --query 'KeyPairs[0].KeyName' --output text 2>/dev/null; then 
            aws ec2 create-key-pair --key-name "actions_key" --query 'KeyName' --output text && echo "Key pair 'actions_key' created in AWS"; 
          else 
            echo "Key pair 'actions_key' already exists"; 
          fi

      - name: Start and monitor Step Functions execution
        run: |
          cd research_datastream/terraform_community
          execution_arn=$(aws stepfunctions start-execution --state-machine-arn $(cat ./sm_ARN.txt) --name fp_test_$(env TZ=US/Eastern date +'%Y%m%d%H%M%S') --input "file://temp.json" --region us-east-1 --query 'executionArn' --output text)
          echo "Execution ARN: $execution_arn"
          status="RUNNING"
          max_wait_time=3600  # 1 hour timeout
          wait_time=0
          while [ "$status" != "SUCCEEDED" ]; do
            status=$(aws stepfunctions describe-execution --execution-arn "$execution_arn" --region us-east-1 --query 'status' --output text)
            echo "Current status: $status (waited ${wait_time}s)"
            if [ "$status" == "FAILED" ]; then
              echo "State machine execution failed!"
              exit 1
            fi
            if [ $wait_time -ge $max_wait_time ]; then
              echo "Timeout waiting for Step Functions execution"
              exit 1
            fi
            sleep 30
            wait_time=$((wait_time + 30))
          done
          echo "State machine execution succeeded!"

      - name: Verify output files exist
        run: |
          echo "Checking if processing created any output files for FP..."
          file_list=$(aws s3 ls s3://ciroh-community-ngen-datastream/tests/short_range/fp/ --recursive 2>/dev/null || echo "")
          
          if [ -n "$file_list" ]; then
            echo "SUCCESS: FP processing completed successfully!"
            echo "Files created:"
            echo "$file_list"
          else
            echo "FAILED: No output files were created for FP"
            exit 1
          fi

      - name: Clean up
        if: always()
        run: |
          aws s3 rm --recursive s3://ciroh-community-ngen-datastream/tests/short_range/fp || echo "No files to delete"

  test-all-vpus:
    needs: [build-test-push-ami, get-ami-info]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        vpu: ["01", "02", "03N", "03S", "03W", "04", "05", "06", "07", "08", "09", "10L", "10U", "11", "12", "13", "14", "15", "16", "17", "18"]    
    env:
      VPU: ${{ matrix.vpu }}
      DATE: 20250801
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq
          pip install --upgrade awscli

      - name: Download and modify execution JSON
        run: |
          cd research_datastream/terraform_community
          
          # Use the AMI ID from the get-ami-info job
          ami_id="${{ needs.get-ami-info.outputs.ami_id }}"
          ami_name="datastream-${{ needs.build-test-push-ami.outputs.ds_ami_version }}"
          
          # Verify AMI ID is valid
          if [ "$ami_id" == "None" ] || [ "$ami_id" == "" ] || [ "$ami_id" == "null" ]; then
            echo "Invalid AMI ID: $ami_id"
            echo "Available AMIs:"
            aws ec2 describe-images --owners self --query 'Images[*].[Name,ImageId]' --output table --region us-east-1
            exit 1
          fi
          
          echo "Using AMI ID: $ami_id for AMI name: $ami_name"
          echo "Testing VPU ${{ env.VPU }} with Docker versions: DS=${{ needs.build-test-push-ami.outputs.ds_tag }}, FP=${{ needs.build-test-push-ami.outputs.fp_tag }}, NGIAB=${{ needs.build-test-push-ami.outputs.ngiab_tag }}"
          
          # Download the proven working execution JSON from S3
          aws s3 cp s3://ciroh-community-ngen-datastream/v2.2/ngen.${{ env.DATE }}/short_range/00/VPU_16/datastream-metadata/execution.json execution.json
          
          # Replace the working AMI with custom one
          jq --arg ami "$ami_id" '.instance_parameters.ImageId = $ami' execution.json > execution_updated.json
          mv execution_updated.json execution.json
          
          # Replace Docker image tags with manually specified versions
          sed -i "s|DS_TAG=1.0.1|DS_TAG=${{ needs.build-test-push-ami.outputs.ds_tag }}|g" execution.json
          sed -i "s|NGIAB_TAG=v0.0.0|NGIAB_TAG=${{ needs.build-test-push-ami.outputs.ngiab_tag }}|g" execution.json

          # Show key info
          echo "AMI replacement completed for VPU ${{ env.VPU }}"
          echo "New AMI ID: $(jq -r '.instance_parameters.ImageId' execution.json)"
          
          # Apply jq transformations for this specific VPU
          jq --arg DATE "${{ env.DATE }}" --arg VPU "${{ env.VPU }}" 'del(.instance_parameters.MaxCount, .instance_parameters.MinCount, .instance_parameters.InstanceId, .t0, .ii_s3_object_checked, .retry_attempt, .region) | .instance_parameters.TagSpecifications = [{"ResourceType": "instance", "Tags": [{"Key": "Project", "Value": "fp_test_git_actions_vpu_\($VPU)"}, {"Key": "AMI_Version", "Value": "datastream-${{ needs.build-test-push-ami.outputs.ds_ami_version }}"}, {"Key": "DS_TAG", "Value": "${{ needs.build-test-push-ami.outputs.ds_tag }}"}, {"Key": "NGIAB_TAG", "Value": "${{ needs.build-test-push-ami.outputs.ngiab_tag }}"}]}] | .commands |= map(sub("--S3_PREFIX(?i) \\K[^ ]+"; "tests/short_range/VPU_\($VPU)'\''")) | .commands |= map(gsub("VPU_16"; "VPU_\($VPU)")) | .commands |= map(gsub("-s DAILY"; "-s DAILY -e \($DATE)0000"))' execution.json > temp.json

      - name: Check and create AWS key pair
        run: |
          cd research_datastream/terraform_community
          if ! aws ec2 describe-key-pairs --key-names "actions_key" --query 'KeyPairs[0].KeyName' --output text 2>/dev/null; then 
            aws ec2 create-key-pair --key-name "actions_key" --query 'KeyName' --output text && echo "Key pair 'actions_key' created in AWS"; 
          else 
            echo "Key pair 'actions_key' already exists"; 
          fi

      - name: Start and monitor Step Functions execution
        id: stepfunction
        run: |
          cd research_datastream/terraform_community
          execution_arn=$(aws stepfunctions start-execution --state-machine-arn $(cat ./sm_ARN.txt) --name VPU_${{ env.VPU }}_test_$(env TZ=US/Eastern date +'%Y%m%d%H%M%S') --input "file://temp.json" --region us-east-1 --query 'executionArn' --output text)
          echo "Execution ARN: $execution_arn"
          status="RUNNING"
          max_wait_time=3600  # 1 hour timeout
          wait_time=0
          while [ "$status" != "SUCCEEDED" ]; do
            status=$(aws stepfunctions describe-execution --execution-arn "$execution_arn" --region us-east-1 --query 'status' --output text)
            echo "Current status: $status (waited ${wait_time}s)"
            if [ "$status" == "FAILED" ]; then
              echo "State machine execution failed for VPU ${{ env.VPU }}!"
              exit 1
            fi
            if [ $wait_time -ge $max_wait_time ]; then
              echo "Timeout waiting for Step Functions execution for VPU ${{ env.VPU }}"
              exit 1
            fi
            sleep 30
            wait_time=$((wait_time + 30))
          done
          echo "State machine execution succeeded for VPU ${{ env.VPU }}!"

      - name: Verify output files
        if: matrix.vpu != '10U' && matrix.vpu != '17'
        run: |
          echo "Checking if processing created any output files for VPU ${{ env.VPU }}..."
          
          # Check if the directory exists and has files
          file_list=$(aws s3 ls s3://ciroh-community-ngen-datastream/tests/short_range/VPU_${{ env.VPU }}/ --recursive 2>/dev/null || echo "")
          
          if [ -n "$file_list" ]; then
            echo "SUCCESS: VPU ${{ env.VPU }} datastream processing completed successfully!"
            echo "Files created:"
            echo "$file_list"
            
            # Count files for summary
            file_count=$(echo "$file_list" | wc -l)
            echo "Total files/objects created for VPU ${{ env.VPU }}: $file_count"
          else
            echo "FAILED: No output files were created for VPU ${{ env.VPU }}"
            exit 1
          fi

      - name: Skip verification notice
        if: matrix.vpu == '10U' || matrix.vpu == '17'
        run: |
          echo "NOTICE: Skipping output file verification for VPU ${{ env.VPU }} (known to have issues)"
          echo "Step Function execution completed successfully, but output verification is bypassed"

      - name: Verify specific output file
        if: matrix.vpu != '10U' && matrix.vpu != '17'
        run: |
          curl -fSs -o test.txt https://ciroh-community-ngen-datastream.s3.amazonaws.com/tests/short_range/VPU_${{ env.VPU }}/merkdir.file || { echo "Error: File not found or request failed"; exit 1; }

      - name: Clean up
        if: always()
        run: |
          aws s3 rm --recursive s3://ciroh-community-ngen-datastream/tests/short_range/VPU_${{ env.VPU }} || echo "No files to delete for VPU ${{ env.VPU }}"

  # Summary job that runs after all VPUs complete
  test-summary:
    runs-on: ubuntu-latest
    needs: [build-test-push-ami, test-all-vpus, get-ami-info, test-research-datastream-forcingprocessing]
    if: always()
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1

      - name: Check Test Results and Handle AMI
        run: |
          echo "Testing Summary:"
          echo "======================"
          echo "Date: $(date)"
          echo "Docker versions tested:"
          echo "  DS_TAG: ${{ needs.build-test-push-ami.outputs.ds_tag }}"
          echo "  FP_TAG: ${{ needs.build-test-push-ami.outputs.fp_tag }}"
          echo "  NGIAB_TAG: ${{ needs.build-test-push-ami.outputs.ngiab_tag }}"
          echo "AMI Version: ${{ needs.build-test-push-ami.outputs.ds_ami_version }}"
          echo ""
          
          # Check test results
          any_failed=false
          
          if [ "${{ needs.test-all-vpus.result }}" != "success" ]; then
            any_failed=true
            echo "VPU tests failed"
          fi
          
          if [ "${{ needs.test-research-datastream-forcingprocessing.result }}" != "success" ]; then
            any_failed=true
            echo "Forcing processing test failed"
          fi
          
          if [ "$any_failed" = "false" ]; then
            echo "All tests passed successfully"
          fi
          
          echo "any_failed=$any_failed" >> $GITHUB_ENV

      - name: Deregister AMI on any test failure
        if: env.any_failed == 'true'
        run: |
          echo "Tests failed - cleaning up AMI..."
          ami_id="${{ needs.get-ami-info.outputs.ami_id }}"
          
          if [ "$ami_id" != "None" ] && [ "$ami_id" != "" ] && [ "$ami_id" != "null" ]; then
            echo "Deregistering AMI: $ami_id"
            
            # Get snapshot IDs before deregistering
            snapshot_ids=$(aws ec2 describe-images --image-ids $ami_id --query 'Images[0].BlockDeviceMappings[*].Ebs.SnapshotId' --output text --region us-east-1 2>/dev/null || echo "")
            
            # Deregister AMI
            aws ec2 deregister-image --image-id $ami_id --region us-east-1
            echo "AMI $ami_id deregistered successfully"
            
            # Delete associated snapshots
            if [ -n "$snapshot_ids" ]; then
              for snapshot_id in $snapshot_ids; do
                if [ "$snapshot_id" != "None" ] && [ "$snapshot_id" != "" ] && [ "$snapshot_id" != "null" ]; then
                  echo "Deleting snapshot: $snapshot_id"
                  aws ec2 delete-snapshot --snapshot-id $snapshot_id --region us-east-1
                fi
              done
            fi
            
            echo "AMI cleanup completed due to test failures"
          fi

      - name: Final Summary
        run: |
          echo "Final Results:"
          
          if [ "${{ env.any_failed }}" == "true" ]; then
            echo "OVERALL RESULT: Tests failed"
            echo "Custom AMI has been deregistered"
            echo "Review failed test logs for troubleshooting"
            exit 1
          else
            echo "OVERALL RESULT: All tests passed successfully"
            echo "Custom AMI validated and preserved for production"
            echo "Docker versions validated:"
            echo "  DS: ${{ needs.build-test-push-ami.outputs.ds_tag }}"
            echo "  FP: ${{ needs.build-test-push-ami.outputs.fp_tag }}" 
            echo "  NGIAB: ${{ needs.build-test-push-ami.outputs.ngiab_tag }}"
          fi
